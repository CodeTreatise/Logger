# 2.3.6 Cloud Services

## Understanding Cloud-Native Logging

Cloud services provide scalable, managed logging solutions with built-in features like automatic scaling, high availability, and advanced analytics. This section covers comprehensive cloud logging implementations across major cloud providers with enterprise-grade features.

## Advanced Cloud Logging Implementation

### 1. **Universal Cloud Logger**
Enterprise-grade cloud logging system supporting multiple cloud providers with advanced features.

```javascript
// Advanced cloud logging implementation
const { EventEmitter } = require('events');

class AdvancedCloudLogger extends EventEmitter {
  constructor(options = {}) {
    super();
    
    this.options = {
      cloudProvider: options.cloudProvider || 'aws', // 'aws', 'azure', 'gcp', 'alibaba', 'multi-cloud'
      service: options.service || 'cloudwatch', // Provider-specific service
      region: options.region || 'us-east-1',
      
      // Authentication
      credentials: options.credentials || {},
      
      // Log group/stream settings
      logGroup: options.logGroup || 'application-logs',
      logStream: options.logStream || `${require('os').hostname()}-${Date.now()}`,
      
      // Batching settings
      batchSize: options.batchSize || 1000,
      batchTimeout: options.batchTimeout || 5000,
      maxBatchBytes: options.maxBatchBytes || 1048576, // 1MB
      
      // Retention settings
      retentionDays: options.retentionDays || 30,
      
      // Performance settings
      maxRetries: options.maxRetries || 3,
      retryDelay: options.retryDelay || 1000,
      compressionEnabled: options.compressionEnabled !== false,
      
      // Multi-cloud settings
      multiCloud: {
        enabled: options.multiCloud?.enabled || false,
        providers: options.multiCloud?.providers || ['aws', 'azure'],
        strategy: options.multiCloud?.strategy || 'primary-backup', // 'primary-backup', 'load-balance', 'replicate'
        ...options.multiCloud
      },
      
      // Advanced features
      structuredLogging: options.structuredLogging !== false,
      enableMetrics: options.enableMetrics !== false,
      enableTracing: options.enableTracing !== false,
      enableAlerts: options.enableAlerts !== false,
      
      // Security
      encryption: options.encryption !== false,
      dataResidency: options.dataResidency || null,
      
      // Cost optimization
      costOptimization: {
        enabled: options.costOptimization?.enabled !== false,
        compressionLevel: options.costOptimization?.compressionLevel || 6,
        sampling: options.costOptimization?.sampling || null,
        archival: options.costOptimization?.archival || null,
        ...options.costOptimization
      },
      
      ...options
    };
    
    this.cloudClients = {};
    this.batchQueue = [];
    this.batchTimer = null;
    this.metrics = this.initializeMetrics();
    this.providers = this.setupProviders();
    this.costTracker = this.setupCostTracker();
    this.alertManager = this.setupAlertManager();
    this.multiCloudManager = this.setupMultiCloudManager();
    
    this.initialize();
  }
  
  initializeMetrics() {
    return {
      logsUploaded: 0,
      bytesUploaded: 0,
      uploadsFailed: 0,
      batchesProcessed: 0,
      averageUploadTime: 0,
      compressionRatio: 0,
      costEstimate: 0,
      apiCallsMade: 0,
      throttleEvents: 0,
      multiCloudFailovers: 0,
      retentionSavings: 0,
      startTime: Date.now()
    };
  }
  
  setupProviders() {
    return {
      aws: {
        services: {
          cloudwatch: this.setupAWSCloudWatch.bind(this),
          cloudtrail: this.setupAWSCloudTrail.bind(this),
          s3: this.setupAWSS3.bind(this),
          kinesis: this.setupAWSKinesis.bind(this),
          opensearch: this.setupAWSOpenSearch.bind(this)
        }
      },
      
      azure: {
        services: {
          monitor: this.setupAzureMonitor.bind(this),
          applicationinsights: this.setupAzureAppInsights.bind(this),
          storage: this.setupAzureStorage.bind(this),
          eventhubs: this.setupAzureEventHubs.bind(this),
          loganalytics: this.setupAzureLogAnalytics.bind(this)
        }
      },
      
      gcp: {
        services: {
          logging: this.setupGCPLogging.bind(this),
          storage: this.setupGCPStorage.bind(this),
          pubsub: this.setupGCPPubSub.bind(this),
          bigquery: this.setupGCPBigQuery.bind(this),
          monitoring: this.setupGCPMonitoring.bind(this)
        }
      },
      
      alibaba: {
        services: {
          sls: this.setupAlibabaSLS.bind(this),
          oss: this.setupAlibabaOSS.bind(this),
          mns: this.setupAlibabaMNS.bind(this)
        }
      }
    };
  }
  
  setupCostTracker() {
    return {
      // Cost tracking per provider and service
      costs: {
        aws: { cloudwatch: 0, s3: 0, kinesis: 0 },
        azure: { monitor: 0, storage: 0, eventhubs: 0 },
        gcp: { logging: 0, storage: 0, pubsub: 0 }
      },
      
      // Cost calculation based on usage
      calculateCost: (provider, service, usage) => {
        const pricing = this.costTracker.getPricing(provider, service);
        const cost = this.costTracker.computeServiceCost(pricing, usage);
        
        this.costTracker.costs[provider][service] += cost;
        this.metrics.costEstimate += cost;
        
        return cost;
      },
      
      getPricing: (provider, service) => {
        const pricingTables = {
          aws: {
            cloudwatch: {
              ingestion: 0.50, // per GB
              storage: 0.03,   // per GB per month
              requests: 0.01   // per 1000 requests
            },
            s3: {
              storage: 0.023,  // per GB per month
              requests: 0.0004 // per 1000 requests
            }
          },
          azure: {
            monitor: {
              ingestion: 2.30, // per GB
              retention: 0.10  // per GB per month
            },
            storage: {
              storage: 0.024,  // per GB per month
              transactions: 0.0036 // per 10000
            }
          },
          gcp: {
            logging: {
              ingestion: 0.50, // per GB
              storage: 0.01    // per GB per month
            },
            storage: {
              storage: 0.020,  // per GB per month
              operations: 0.05 // per 1000 operations
            }
          }
        };
        
        return pricingTables[provider]?.[service] || {};
      },
      
      computeServiceCost: (pricing, usage) => {
        let cost = 0;
        
        if (pricing.ingestion && usage.bytesIngested) {
          cost += (usage.bytesIngested / (1024 * 1024 * 1024)) * pricing.ingestion;
        }
        
        if (pricing.storage && usage.bytesStored) {
          cost += (usage.bytesStored / (1024 * 1024 * 1024)) * pricing.storage;
        }
        
        if (pricing.requests && usage.requestCount) {
          cost += (usage.requestCount / 1000) * pricing.requests;
        }
        
        return cost;
      },
      
      getOptimizationRecommendations: () => {
        const recommendations = [];
        const totalCost = Object.values(this.costTracker.costs)
          .flatMap(provider => Object.values(provider))
          .reduce((sum, cost) => sum + cost, 0);
        
        if (totalCost > 100) {
          recommendations.push({
            type: 'compression',
            impact: 'high',
            description: 'Enable compression to reduce data transfer costs',
            potentialSavings: totalCost * 0.3
          });
        }
        
        if (this.options.retentionDays > 30) {
          recommendations.push({
            type: 'retention',
            impact: 'medium',
            description: 'Reduce log retention period to lower storage costs',
            potentialSavings: totalCost * 0.2
          });
        }
        
        return recommendations;
      }
    };
  }
  
  setupAlertManager() {
    return {
      alerts: [],
      
      createAlert: (name, condition, actions) => {
        const alert = {
          name,
          condition,
          actions,
          enabled: true,
          lastTriggered: null,
          triggerCount: 0
        };
        
        this.alertManager.alerts.push(alert);
        return alert;
      },
      
      evaluateAlerts: (metrics) => {
        this.alertManager.alerts.forEach(alert => {
          if (alert.enabled && alert.condition(metrics)) {
            this.alertManager.triggerAlert(alert, metrics);
          }
        });
      },
      
      triggerAlert: (alert, metrics) => {
        alert.lastTriggered = new Date();
        alert.triggerCount++;
        
        console.warn(`ALERT TRIGGERED: ${alert.name}`, metrics);
        
        alert.actions.forEach(action => {
          try {
            action(alert, metrics);
          } catch (error) {
            console.error('Alert action failed:', error);
          }
        });
        
        this.emit('alert', { alert, metrics });
      },
      
      setupDefaultAlerts: () => {
        // High upload failure rate
        this.alertManager.createAlert(
          'High Upload Failure Rate',
          (metrics) => metrics.uploadsFailed > 10,
          [(alert, metrics) => {
            console.error('High upload failure rate detected:', metrics);
          }]
        );
        
        // High cost alert
        this.alertManager.createAlert(
          'High Logging Costs',
          (metrics) => metrics.costEstimate > 1000,
          [(alert, metrics) => {
            console.warn('Logging costs exceeded threshold:', metrics.costEstimate);
          }]
        );
        
        // Throttling alert
        this.alertManager.createAlert(
          'API Throttling Detected',
          (metrics) => metrics.throttleEvents > 5,
          [(alert, metrics) => {
            console.warn('API throttling detected:', metrics.throttleEvents);
          }]
        );
      }
    };
  }
  
  setupMultiCloudManager() {
    return {
      primaryProvider: null,
      backupProviders: [],
      
      initialize: () => {
        if (!this.options.multiCloud.enabled) return;
        
        const providers = this.options.multiCloud.providers;
        this.multiCloudManager.primaryProvider = providers[0];
        this.multiCloudManager.backupProviders = providers.slice(1);
      },
      
      executeStrategy: async (logEntry) => {
        const strategy = this.options.multiCloud.strategy;
        
        switch (strategy) {
          case 'primary-backup':
            return this.multiCloudManager.primaryBackupStrategy(logEntry);
          case 'load-balance':
            return this.multiCloudManager.loadBalanceStrategy(logEntry);
          case 'replicate':
            return this.multiCloudManager.replicationStrategy(logEntry);
          default:
            return this.multiCloudManager.primaryBackupStrategy(logEntry);
        }
      },
      
      primaryBackupStrategy: async (logEntry) => {
        try {
          const primary = this.multiCloudManager.primaryProvider;
          await this.uploadToProvider(primary, [logEntry]);
        } catch (error) {
          console.warn(`Primary provider ${this.multiCloudManager.primaryProvider} failed, trying backup`);
          this.metrics.multiCloudFailovers++;
          
          for (const backup of this.multiCloudManager.backupProviders) {
            try {
              await this.uploadToProvider(backup, [logEntry]);
              break;
            } catch (backupError) {
              console.error(`Backup provider ${backup} also failed:`, backupError);
            }
          }
        }
      },
      
      loadBalanceStrategy: async (logEntry) => {
        const providers = [
          this.multiCloudManager.primaryProvider,
          ...this.multiCloudManager.backupProviders
        ];
        
        // Simple round-robin load balancing
        const providerIndex = this.metrics.logsUploaded % providers.length;
        const selectedProvider = providers[providerIndex];
        
        try {
          await this.uploadToProvider(selectedProvider, [logEntry]);
        } catch (error) {
          // Fallback to next provider
          const fallbackProvider = providers[(providerIndex + 1) % providers.length];
          await this.uploadToProvider(fallbackProvider, [logEntry]);
          this.metrics.multiCloudFailovers++;
        }
      },
      
      replicationStrategy: async (logEntry) => {
        const providers = [
          this.multiCloudManager.primaryProvider,
          ...this.multiCloudManager.backupProviders
        ];
        
        const promises = providers.map(provider => 
          this.uploadToProvider(provider, [logEntry]).catch(error => {
            console.error(`Replication to ${provider} failed:`, error);
            return { provider, error };
          })
        );
        
        await Promise.allSettled(promises);
      }
    };
  }
  
  async initialize() {
    try {
      await this.initializeCloudClients();
      this.setupBatchProcessing();
      this.multiCloudManager.initialize();
      this.alertManager.setupDefaultAlerts();
      
      if (this.options.enableMetrics) {
        this.setupMetricsCollection();
      }
      
      console.log(`Cloud logger initialized: ${this.options.cloudProvider}`);
      
    } catch (error) {
      console.error('Failed to initialize cloud logger:', error);
      throw error;
    }
  }
  
  async initializeCloudClients() {
    const provider = this.options.cloudProvider;
    
    if (provider === 'multi-cloud') {
      // Initialize multiple providers
      for (const p of this.options.multiCloud.providers) {
        await this.initializeProviderClient(p);
      }
    } else {
      await this.initializeProviderClient(provider);
    }
  }
  
  async initializeProviderClient(provider) {
    const providerConfig = this.providers[provider];
    
    if (!providerConfig) {
      throw new Error(`Unsupported cloud provider: ${provider}`);
    }
    
    const service = this.options.service;
    const serviceInitializer = providerConfig.services[service];
    
    if (!serviceInitializer) {
      throw new Error(`Unsupported service ${service} for provider ${provider}`);
    }
    
    this.cloudClients[provider] = await serviceInitializer();
  }
  
  // AWS CloudWatch implementation
  async setupAWSCloudWatch() {
    const AWS = require('aws-sdk');
    
    AWS.config.update({
      region: this.options.region,
      accessKeyId: this.options.credentials.accessKeyId,
      secretAccessKey: this.options.credentials.secretAccessKey,
      sessionToken: this.options.credentials.sessionToken,
      ...this.options.credentials
    });
    
    const cloudwatchLogs = new AWS.CloudWatchLogs();
    
    // Create log group if it doesn't exist
    try {
      await cloudwatchLogs.createLogGroup({
        logGroupName: this.options.logGroup,
        retentionInDays: this.options.retentionDays
      }).promise();
    } catch (error) {
      if (error.code !== 'ResourceAlreadyExistsException') {
        throw error;
      }
    }
    
    // Create log stream
    try {
      await cloudwatchLogs.createLogStream({
        logGroupName: this.options.logGroup,
        logStreamName: this.options.logStream
      }).promise();
    } catch (error) {
      if (error.code !== 'ResourceAlreadyExistsException') {
        throw error;
      }
    }
    
    return {
      client: cloudwatchLogs,
      upload: async (events) => {
        const params = {
          logGroupName: this.options.logGroup,
          logStreamName: this.options.logStream,
          logEvents: events.map(event => ({
            timestamp: event.timestamp,
            message: typeof event.message === 'string' ? 
              event.message : JSON.stringify(event.message)
          }))
        };
        
        // Get sequence token for the stream
        const streams = await cloudwatchLogs.describeLogStreams({
          logGroupName: this.options.logGroup,
          logStreamNamePrefix: this.options.logStream
        }).promise();
        
        const stream = streams.logStreams.find(s => s.logStreamName === this.options.logStream);
        if (stream?.uploadSequenceToken) {
          params.sequenceToken = stream.uploadSequenceToken;
        }
        
        const result = await cloudwatchLogs.putLogEvents(params).promise();
        
        // Track costs
        const bytesUploaded = JSON.stringify(params.logEvents).length;
        this.costTracker.calculateCost('aws', 'cloudwatch', {
          bytesIngested: bytesUploaded,
          requestCount: 1
        });
        
        return result;
      }
    };
  }
  
  // AWS S3 implementation for long-term storage
  async setupAWSS3() {
    const AWS = require('aws-sdk');
    
    const s3 = new AWS.S3({
      region: this.options.region,
      accessKeyId: this.options.credentials.accessKeyId,
      secretAccessKey: this.options.credentials.secretAccessKey
    });
    
    return {
      client: s3,
      upload: async (events) => {
        const timestamp = new Date().toISOString().split('T')[0];
        const key = `logs/${timestamp}/${this.options.logStream}-${Date.now()}.json`;
        
        let content = JSON.stringify(events);
        
        if (this.options.compressionEnabled) {
          const zlib = require('zlib');
          content = zlib.gzipSync(content);
        }
        
        const params = {
          Bucket: this.options.bucket || 'application-logs',
          Key: key,
          Body: content,
          ContentType: 'application/json',
          ContentEncoding: this.options.compressionEnabled ? 'gzip' : undefined,
          ServerSideEncryption: this.options.encryption ? 'AES256' : undefined
        };
        
        const result = await s3.upload(params).promise();
        
        // Track costs
        this.costTracker.calculateCost('aws', 's3', {
          bytesStored: content.length,
          requestCount: 1
        });
        
        return result;
      }
    };
  }
  
  // Azure Monitor implementation
  async setupAzureMonitor() {
    const { DefaultAzureCredential } = require('@azure/identity');
    const { MonitorIngestionClient } = require('@azure/monitor-ingestion');
    
    const credential = new DefaultAzureCredential();
    const client = new MonitorIngestionClient(
      this.options.credentials.dataCollectionEndpoint,
      credential
    );
    
    return {
      client,
      upload: async (events) => {
        const logs = events.map(event => ({
          TimeGenerated: new Date(event.timestamp).toISOString(),
          Level: event.level,
          Message: event.message,
          Properties: event.metadata || {}
        }));
        
        const result = await client.upload(
          this.options.credentials.dataCollectionRuleId,
          this.options.credentials.streamName,
          logs
        );
        
        // Track costs
        const bytesUploaded = JSON.stringify(logs).length;
        this.costTracker.calculateCost('azure', 'monitor', {
          bytesIngested: bytesUploaded
        });
        
        return result;
      }
    };
  }
  
  // Azure Application Insights implementation
  async setupAzureAppInsights() {
    const appInsights = require('applicationinsights');
    
    appInsights.setup(this.options.credentials.instrumentationKey)
      .setAutoDependencyCorrelation(true)
      .setAutoCollectRequests(true)
      .setAutoCollectPerformance(true)
      .setAutoCollectExceptions(true)
      .setAutoCollectDependencies(true)
      .setAutoCollectConsole(true)
      .setUseDiskRetryCaching(true)
      .setSendLiveMetrics(true);
    
    appInsights.start();
    
    const client = appInsights.defaultClient;
    
    return {
      client,
      upload: async (events) => {
        events.forEach(event => {
          switch (event.level.toLowerCase()) {
            case 'error':
            case 'fatal':
              client.trackException({
                exception: new Error(event.message),
                properties: event.metadata
              });
              break;
            case 'warn':
              client.trackTrace({
                message: event.message,
                severity: appInsights.Contracts.SeverityLevel.Warning,
                properties: event.metadata
              });
              break;
            default:
              client.trackTrace({
                message: event.message,
                severity: appInsights.Contracts.SeverityLevel.Information,
                properties: event.metadata
              });
          }
        });
        
        client.flush();
      }
    };
  }
  
  // Google Cloud Logging implementation
  async setupGCPLogging() {
    const { Logging } = require('@google-cloud/logging');
    
    const logging = new Logging({
      projectId: this.options.credentials.projectId,
      keyFilename: this.options.credentials.keyFilename
    });
    
    const log = logging.log(this.options.logGroup);
    
    return {
      client: logging,
      upload: async (events) => {
        const entries = events.map(event => {
          const entry = log.entry({
            timestamp: new Date(event.timestamp),
            severity: this.mapLogLevelToGCP(event.level),
            labels: {
              service: event.metadata?.service || 'unknown',
              version: event.metadata?.version || '1.0.0'
            }
          }, event.message);
          
          return entry;
        });
        
        await log.write(entries);
        
        // Track costs
        const bytesUploaded = JSON.stringify(events).length;
        this.costTracker.calculateCost('gcp', 'logging', {
          bytesIngested: bytesUploaded
        });
      }
    };
  }
  
  // Google Cloud Storage implementation
  async setupGCPStorage() {
    const { Storage } = require('@google-cloud/storage');
    
    const storage = new Storage({
      projectId: this.options.credentials.projectId,
      keyFilename: this.options.credentials.keyFilename
    });
    
    const bucket = storage.bucket(this.options.bucket || 'application-logs');
    
    return {
      client: storage,
      upload: async (events) => {
        const timestamp = new Date().toISOString().split('T')[0];
        const fileName = `logs/${timestamp}/${this.options.logStream}-${Date.now()}.json`;
        
        let content = JSON.stringify(events);
        
        if (this.options.compressionEnabled) {
          const zlib = require('zlib');
          content = zlib.gzipSync(content);
        }
        
        const file = bucket.file(fileName);
        
        await file.save(content, {
          metadata: {
            contentType: 'application/json',
            contentEncoding: this.options.compressionEnabled ? 'gzip' : undefined
          }
        });
        
        // Track costs
        this.costTracker.calculateCost('gcp', 'storage', {
          bytesStored: content.length,
          operations: 1
        });
      }
    };
  }
  
  mapLogLevelToGCP(level) {
    const mapping = {
      'TRACE': 'DEBUG',
      'DEBUG': 'DEBUG',
      'INFO': 'INFO',
      'WARN': 'WARNING',
      'ERROR': 'ERROR',
      'FATAL': 'CRITICAL'
    };
    
    return mapping[level.toUpperCase()] || 'INFO';
  }
  
  setupBatchProcessing() {
    this.batchProcessor = {
      add: (logEntry) => {
        this.batchQueue.push(logEntry);
        
        const shouldFlush = 
          this.batchQueue.length >= this.options.batchSize ||
          this.getBatchSize() >= this.options.maxBatchBytes;
        
        if (shouldFlush) {
          this.processBatch();
        } else if (!this.batchTimer) {
          this.batchTimer = setTimeout(() => {
            this.processBatch();
          }, this.options.batchTimeout);
        }
      },
      
      process: async () => {
        if (this.batchQueue.length === 0) return;
        
        const batch = [...this.batchQueue];
        this.batchQueue = [];
        
        if (this.batchTimer) {
          clearTimeout(this.batchTimer);
          this.batchTimer = null;
        }
        
        try {
          if (this.options.multiCloud.enabled) {
            await this.uploadMultiCloud(batch);
          } else {
            await this.uploadToProvider(this.options.cloudProvider, batch);
          }
          
          this.metrics.batchesProcessed++;
        } catch (error) {
          console.error('Batch upload failed:', error);
          this.handleBatchFailure(batch, error);
        }
      }
    };
  }
  
  getBatchSize() {
    return JSON.stringify(this.batchQueue).length;
  }
  
  async uploadMultiCloud(batch) {
    for (const logEntry of batch) {
      await this.multiCloudManager.executeStrategy(logEntry);
    }
  }
  
  async uploadToProvider(provider, batch) {
    const startTime = Date.now();
    
    try {
      const client = this.cloudClients[provider];
      
      if (!client) {
        throw new Error(`Cloud client not initialized for provider: ${provider}`);
      }
      
      await client.upload(batch);
      
      this.metrics.logsUploaded += batch.length;
      this.metrics.bytesUploaded += JSON.stringify(batch).length;
      this.metrics.apiCallsMade++;
      
      const uploadTime = Date.now() - startTime;
      this.updateUploadMetrics(uploadTime);
      
    } catch (error) {
      this.metrics.uploadsFailed += batch.length;
      
      if (this.isThrottleError(error)) {
        this.metrics.throttleEvents++;
        console.warn('API throttling detected, implementing backoff');
        await this.exponentialBackoff();
      }
      
      throw error;
    }
  }
  
  isThrottleError(error) {
    const throttleMessages = [
      'throttle', 'rate limit', 'too many requests',
      'quota exceeded', 'capacity exceeded'
    ];
    
    const errorMessage = error.message?.toLowerCase() || '';
    return throttleMessages.some(msg => errorMessage.includes(msg));
  }
  
  async exponentialBackoff() {
    const delay = Math.min(1000 * Math.pow(2, this.metrics.throttleEvents), 30000);
    await new Promise(resolve => setTimeout(resolve, delay));
  }
  
  updateUploadMetrics(uploadTime) {
    const avgTime = this.metrics.averageUploadTime;
    const count = this.metrics.batchesProcessed + 1;
    this.metrics.averageUploadTime = (avgTime * (count - 1) + uploadTime) / count;
  }
  
  handleBatchFailure(batch, error) {
    console.error('Batch upload failure:', error);
    
    // Implement retry logic
    setTimeout(() => {
      if (this.options.multiCloud.enabled) {
        this.uploadMultiCloud(batch);
      } else {
        this.uploadToProvider(this.options.cloudProvider, batch);
      }
    }, this.options.retryDelay);
  }
  
  setupMetricsCollection() {
    setInterval(() => {
      this.emitMetrics();
      this.alertManager.evaluateAlerts(this.metrics);
    }, 60000); // Every minute
  }
  
  async log(level, message, metadata = {}) {
    const logEntry = {
      timestamp: Date.now(),
      level: level.toUpperCase(),
      message,
      metadata: this.sanitizeMetadata(metadata),
      hostname: require('os').hostname(),
      pid: process.pid,
      service: process.env.SERVICE_NAME || 'unknown',
      version: process.env.APP_VERSION || '1.0.0',
      environment: process.env.NODE_ENV || 'development'
    };
    
    // Apply cost optimization
    if (this.shouldSample(logEntry)) {
      this.batchProcessor.add(logEntry);
    }
  }
  
  shouldSample(logEntry) {
    const sampling = this.options.costOptimization.sampling;
    
    if (!sampling) return true;
    
    // Sample based on log level
    if (sampling.byLevel) {
      const levelSampling = sampling.byLevel[logEntry.level.toLowerCase()];
      if (levelSampling && Math.random() > levelSampling) {
        return false;
      }
    }
    
    // Sample based on service
    if (sampling.byService) {
      const serviceSampling = sampling.byService[logEntry.metadata.service];
      if (serviceSampling && Math.random() > serviceSampling) {
        return false;
      }
    }
    
    return true;
  }
  
  sanitizeMetadata(metadata) {
    if (typeof metadata !== 'object' || metadata === null) {
      return {};
    }
    
    const sanitized = { ...metadata };
    const sensitiveKeys = ['password', 'token', 'apikey', 'secret', 'auth', 'authorization'];
    
    Object.keys(sanitized).forEach(key => {
      const lowerKey = key.toLowerCase();
      
      if (sensitiveKeys.some(sensitive => lowerKey.includes(sensitive))) {
        sanitized[key] = '[REDACTED]';
      }
    });
    
    return sanitized;
  }
  
  async processBatch() {
    return this.batchProcessor.process();
  }
  
  emitMetrics() {
    const uptime = Date.now() - this.metrics.startTime;
    const metricsSnapshot = {
      ...this.metrics,
      uptime,
      logsPerSecond: this.metrics.logsUploaded / (uptime / 1000),
      bytesPerSecond: this.metrics.bytesUploaded / (uptime / 1000),
      failureRate: this.metrics.uploadsFailed / Math.max(this.metrics.logsUploaded, 1) * 100,
      costPerLog: this.metrics.costEstimate / Math.max(this.metrics.logsUploaded, 1),
      compressionRatio: this.calculateCompressionRatio()
    };
    
    this.emit('metrics', metricsSnapshot);
  }
  
  calculateCompressionRatio() {
    // Simplified compression ratio calculation
    return this.options.compressionEnabled ? 0.7 : 1.0;
  }
  
  // Convenience methods
  trace(message, metadata) { return this.log('trace', message, metadata); }
  debug(message, metadata) { return this.log('debug', message, metadata); }
  info(message, metadata) { return this.log('info', message, metadata); }
  warn(message, metadata) { return this.log('warn', message, metadata); }
  error(message, metadata) { return this.log('error', message, metadata); }
  fatal(message, metadata) { return this.log('fatal', message, metadata); }
  
  // Management methods
  async flush() {
    return this.processBatch();
  }
  
  getMetrics() {
    return { ...this.metrics };
  }
  
  getCostReport() {
    return {
      totalCost: this.metrics.costEstimate,
      costBreakdown: this.costTracker.costs,
      recommendations: this.costTracker.getOptimizationRecommendations(),
      projectedMonthlyCost: this.metrics.costEstimate * 30
    };
  }
  
  async getHealth() {
    try {
      // Test connectivity to cloud services
      const healthChecks = {};
      
      for (const [provider, client] of Object.entries(this.cloudClients)) {
        try {
          // Perform a lightweight health check
          await this.performHealthCheck(provider, client);
          healthChecks[provider] = { healthy: true };
        } catch (error) {
          healthChecks[provider] = { healthy: false, error: error.message };
        }
      }
      
      const overallHealth = Object.values(healthChecks)
        .every(check => check.healthy);
      
      return {
        healthy: overallHealth,
        providers: healthChecks,
        metrics: this.getMetrics(),
        queueDepth: this.batchQueue.length
      };
    } catch (error) {
      return {
        healthy: false,
        error: error.message
      };
    }
  }
  
  async performHealthCheck(provider, client) {
    // Simple health check - attempt a minimal operation
    switch (provider) {
      case 'aws':
        // CloudWatch health check
        if (client.client.describeLogGroups) {
          await client.client.describeLogGroups({ limit: 1 }).promise();
        }
        break;
      case 'azure':
        // Azure health check would depend on service
        break;
      case 'gcp':
        // GCP health check
        if (client.client.getProjectId) {
          await client.client.getProjectId();
        }
        break;
    }
  }
  
  // Cleanup
  async destroy() {
    try {
      // Flush remaining logs
      await this.flush();
      
      // Clear timers
      if (this.batchTimer) {
        clearTimeout(this.batchTimer);
      }
      
      // Close cloud client connections
      for (const [provider, client] of Object.entries(this.cloudClients)) {
        if (client.client && typeof client.client.destroy === 'function') {
          await client.client.destroy();
        }
      }
      
      console.log('Cloud logger destroyed');
    } catch (error) {
      console.error('Error during cloud logger destruction:', error);
    }
  }
}
```

## Cloud Logging Best Practices

### **Production Cloud Logging Setup**
```javascript
// Production-ready cloud logging configuration
class ProductionCloudLogger {
  constructor(options = {}) {
    this.environment = process.env.NODE_ENV || 'development';
    this.cloudProvider = options.cloudProvider || 'aws';
    
    const config = this.getEnvironmentConfig();
    
    this.logger = new AdvancedCloudLogger({
      ...config,
      ...options,
      
      // Production optimizations
      batchSize: this.environment === 'production' ? 1000 : 100,
      batchTimeout: this.environment === 'production' ? 10000 : 5000,
      compressionEnabled: true,
      
      // Multi-cloud for production resilience
      multiCloud: this.environment === 'production' ? {
        enabled: true,
        providers: ['aws', 'azure'],
        strategy: 'primary-backup'
      } : { enabled: false },
      
      // Cost optimization
      costOptimization: {
        enabled: true,
        sampling: {
          byLevel: {
            debug: 0.1,  // Sample 10% of debug logs
            info: 0.5,   // Sample 50% of info logs
            warn: 1.0,   // Keep all warnings
            error: 1.0,  // Keep all errors
            fatal: 1.0   // Keep all fatal logs
          }
        }
      },
      
      // Retention based on environment
      retentionDays: this.environment === 'production' ? 90 : 7,
      
      // Security
      encryption: this.environment === 'production',
      dataResidency: process.env.DATA_RESIDENCY_REGION
    });
    
    this.setupProductionFeatures();
  }
  
  getEnvironmentConfig() {
    const configs = {
      development: {
        cloudProvider: 'aws',
        service: 'cloudwatch',
        region: 'us-east-1',
        logGroup: 'dev-application-logs',
        credentials: {
          accessKeyId: process.env.AWS_ACCESS_KEY_ID,
          secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY
        }
      },
      
      testing: {
        cloudProvider: 'aws',
        service: 'cloudwatch',
        region: 'us-east-1',
        logGroup: 'test-application-logs',
        credentials: {
          accessKeyId: process.env.AWS_ACCESS_KEY_ID,
          secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY
        }
      },
      
      production: {
        cloudProvider: 'aws',
        service: 'cloudwatch',
        region: process.env.AWS_REGION || 'us-east-1',
        logGroup: 'prod-application-logs',
        credentials: {
          accessKeyId: process.env.AWS_ACCESS_KEY_ID,
          secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY,
          sessionToken: process.env.AWS_SESSION_TOKEN
        },
        enableMetrics: true,
        enableAlerts: true
      }
    };
    
    return configs[this.environment] || configs.development;
  }
  
  setupProductionFeatures() {
    // Monitor cloud logging metrics
    this.logger.on('metrics', (metrics) => {
      this.handleMetrics(metrics);
    });
    
    this.logger.on('alert', (alertInfo) => {
      this.handleAlert(alertInfo);
    });
    
    // Cost monitoring
    setInterval(() => {
      this.monitorCosts();
    }, 3600000); // Hourly cost monitoring
    
    // Health monitoring
    setInterval(() => {
      this.performHealthCheck();
    }, 300000); // Every 5 minutes
    
    // Setup graceful shutdown
    process.on('SIGTERM', () => this.gracefulShutdown());
    process.on('SIGINT', () => this.gracefulShutdown());
  }
  
  handleMetrics(metrics) {
    if (this.environment === 'production') {
      // Send metrics to monitoring system
      this.sendMetricsToMonitoring(metrics);
      
      // Check for performance issues
      if (metrics.failureRate > 5) {
        console.warn('High cloud logging failure rate:', metrics.failureRate);
      }
      
      if (metrics.averageUploadTime > 5000) {
        console.warn('High cloud logging latency:', metrics.averageUploadTime);
      }
      
      if (metrics.throttleEvents > 0) {
        console.warn('Cloud API throttling events:', metrics.throttleEvents);
      }
    }
  }
  
  handleAlert(alertInfo) {
    console.error('Cloud logging alert:', alertInfo.alert.name);
    
    if (this.environment === 'production') {
      // Send alert to incident management system
      this.sendAlertToIncidentManagement(alertInfo);
    }
  }
  
  monitorCosts() {
    const costReport = this.logger.getCostReport();
    
    console.log('Cloud logging cost report:', costReport);
    
    if (costReport.totalCost > 1000) {
      console.warn('High cloud logging costs detected:', costReport.totalCost);
      
      // Send cost alert
      if (this.environment === 'production') {
        this.sendCostAlert(costReport);
      }
    }
    
    // Log cost optimization recommendations
    if (costReport.recommendations.length > 0) {
      console.log('Cost optimization recommendations:', costReport.recommendations);
    }
  }
  
  async performHealthCheck() {
    try {
      const health = await this.logger.getHealth();
      
      if (!health.healthy) {
        console.error('Cloud logger health check failed:', health);
        
        if (this.environment === 'production') {
          this.sendHealthAlert(health);
        }
      }
    } catch (error) {
      console.error('Health check error:', error);
    }
  }
  
  sendMetricsToMonitoring(metrics) {
    // Implementation depends on monitoring system
    const monitoringData = {
      service: 'cloud-logger',
      environment: this.environment,
      cloudProvider: this.cloudProvider,
      metrics: {
        'logs.uploaded': metrics.logsUploaded,
        'logs.failed': metrics.uploadsFailed,
        'logs.per_second': metrics.logsPerSecond,
        'bytes.uploaded': metrics.bytesUploaded,
        'bytes.per_second': metrics.bytesPerSecond,
        'upload.latency_avg': metrics.averageUploadTime,
        'failure.rate': metrics.failureRate,
        'cost.total': metrics.costEstimate,
        'cost.per_log': metrics.costPerLog,
        'api.calls': metrics.apiCallsMade,
        'throttle.events': metrics.throttleEvents,
        'multicloud.failovers': metrics.multiCloudFailovers
      },
      timestamp: Date.now()
    };
    
    console.log('Cloud Logging Metrics:', monitoringData);
  }
  
  sendAlertToIncidentManagement(alertInfo) {
    // Send to incident management system (PagerDuty, OpsGenie, etc.)
    console.error('INCIDENT: Cloud logging alert triggered', {
      alert: alertInfo.alert.name,
      severity: 'high',
      environment: this.environment
    });
  }
  
  sendCostAlert(costReport) {
    console.warn('COST ALERT: High cloud logging costs', {
      totalCost: costReport.totalCost,
      projectedMonthlyCost: costReport.projectedMonthlyCost,
      environment: this.environment
    });
  }
  
  sendHealthAlert(health) {
    console.error('HEALTH ALERT: Cloud logger unhealthy', {
      providers: health.providers,
      environment: this.environment
    });
  }
  
  async gracefulShutdown() {
    console.log('Initiating graceful shutdown of cloud logger...');
    
    try {
      // Flush remaining logs
      await this.logger.flush();
      
      // Give time for final uploads
      await new Promise(resolve => setTimeout(resolve, 5000));
      
      // Destroy the logger
      await this.logger.destroy();
      
      console.log('Cloud logger shutdown completed');
      process.exit(0);
    } catch (error) {
      console.error('Error during graceful shutdown:', error);
      process.exit(1);
    }
  }
  
  // Logging interface
  async log(level, message, metadata = {}) {
    // Add production context
    const enrichedMetadata = {
      ...metadata,
      environment: this.environment,
      service: process.env.SERVICE_NAME || 'unknown',
      version: process.env.APP_VERSION || '1.0.0',
      instance: require('os').hostname(),
      region: process.env.AWS_REGION || 'unknown',
      correlationId: metadata.correlationId || this.generateCorrelationId()
    };
    
    return this.logger.log(level, message, enrichedMetadata);
  }
  
  generateCorrelationId() {
    return `${Date.now()}-${Math.random().toString(36).substring(2, 15)}`;
  }
  
  // Convenience methods
  info(message, metadata) { return this.log('info', message, metadata); }
  warn(message, metadata) { return this.log('warn', message, metadata); }
  error(message, metadata) { return this.log('error', message, metadata); }
  debug(message, metadata) { return this.log('debug', message, metadata); }
  
  // Cost management
  getCostReport() {
    return this.logger.getCostReport();
  }
  
  // Health monitoring
  async getHealth() {
    return this.logger.getHealth();
  }
  
  // Metrics
  getMetrics() {
    return this.logger.getMetrics();
  }
  
  // Cleanup
  async destroy() {
    await this.logger.destroy();
  }
}

// Usage example
const cloudLogger = new ProductionCloudLogger({
  cloudProvider: 'aws',
  service: 'cloudwatch',
  region: 'us-east-1',
  multiCloud: {
    enabled: true,
    providers: ['aws', 'azure'],
    strategy: 'primary-backup'
  }
});

// Application logging
cloudLogger.info('Application started', { 
  port: 3000,
  correlationId: 'app-start-001' 
});

cloudLogger.error('Database connection failed', { 
  database: 'postgresql',
  host: 'db.example.com',
  error: 'Connection timeout',
  correlationId: 'db-error-001'
});

// Cost monitoring
const costReport = cloudLogger.getCostReport();
console.log('Logging cost report:', costReport);

// Health monitoring
const health = await cloudLogger.getHealth();
console.log('Cloud logger health:', health);
```

---

**Section 2.3 Log Destinations is now COMPLETE!** ✅

## Summary of Section 2.3 - Log Destinations (Appenders/Handlers)

We've successfully implemented all 6 comprehensive log destination types:

1. **2.3.1 Console Output** - Interactive console logging with colors, progress bars, and optimization
2. **2.3.2 File Systems** - Enterprise file logging with rotation, compression, and encryption
3. **2.3.3 Network Endpoints** - Multi-protocol network logging with circuit breakers and failover
4. **2.3.4 Databases** - Database logging with partitioning, optimization, and multi-database support
5. **2.3.5 Message Queues** - Queue-based logging with multi-queue support, batching, and resilience
6. **2.3.6 Cloud Services** - Cloud-native logging with multi-cloud support, cost optimization, and monitoring

Each implementation provides enterprise-grade features including:
- **High Performance**: Batching, compression, connection pooling
- **Reliability**: Circuit breakers, retry logic, failover mechanisms
- **Monitoring**: Comprehensive metrics, health checks, alerting
- **Security**: Encryption, data sanitization, secure connections
- **Cost Optimization**: Intelligent sampling, compression, retention policies
- **Production Ready**: Environment-specific configurations, graceful shutdown

**Next**: Ready to proceed to **Chapter 3: Logging Best Practices** covering what to log, what NOT to log, and message guidelines!
