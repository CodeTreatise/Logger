# 2.3.5 Message Queues

## Understanding Queue-Based Logging

Message queue logging provides asynchronous, scalable, and fault-tolerant log processing for distributed systems. This approach decouples log generation from log processing, enabling high-throughput applications and resilient distributed architectures.

## Advanced Queue-Based Logging Implementation

### 1. **Universal Queue Logger**
Enterprise-grade message queue logging system supporting multiple queue technologies with advanced features.

```javascript
// Advanced message queue logging implementation
const { EventEmitter } = require('events');

class AdvancedQueueLogger extends EventEmitter {
  constructor(options = {}) {
    super();
    
    this.options = {
      queueType: options.queueType || 'rabbitmq', // 'rabbitmq', 'kafka', 'redis', 'sqs', 'azure-servicebus', 'activemq'
      connection: options.connection || {},
      
      // Queue settings
      queueName: options.queueName || 'application-logs',
      exchangeName: options.exchangeName || 'logs-exchange',
      routingKey: options.routingKey || 'logs.default',
      
      // Message settings
      persistent: options.persistent !== false,
      priority: options.priority || 0,
      ttl: options.ttl || null,
      maxRetries: options.maxRetries || 3,
      
      // Batching settings
      batchSize: options.batchSize || 100,
      batchTimeout: options.batchTimeout || 5000,
      compressionEnabled: options.compressionEnabled !== false,
      
      // Circuit breaker settings
      circuitBreaker: {
        errorThreshold: options.errorThreshold || 5,
        timeout: options.timeout || 60000,
        resetTimeout: options.resetTimeout || 30000,
        ...options.circuitBreaker
      },
      
      // Dead letter queue settings
      deadLetterQueue: {
        enabled: options.deadLetterQueue?.enabled !== false,
        queueName: options.deadLetterQueue?.queueName || `${options.queueName || 'application-logs'}-dlq`,
        maxRetries: options.deadLetterQueue?.maxRetries || 3,
        retryDelay: options.deadLetterQueue?.retryDelay || 5000,
        ...options.deadLetterQueue
      },
      
      // Serialization
      serializer: options.serializer || 'json', // 'json', 'avro', 'protobuf', 'msgpack'
      
      // Performance settings
      connectionPoolSize: options.connectionPoolSize || 10,
      publishConfirms: options.publishConfirms !== false,
      
      // Monitoring
      enableMetrics: options.enableMetrics !== false,
      enableHealthCheck: options.enableHealthCheck !== false,
      
      // Security
      encryption: options.encryption || false,
      authentication: options.authentication || {},
      
      ...options
    };
    
    this.queueClient = null;
    this.connectionPool = [];
    this.batchQueue = [];
    this.batchTimer = null;
    this.circuitBreakerState = 'CLOSED'; // CLOSED, OPEN, HALF_OPEN
    this.circuitBreakerFailures = 0;
    this.circuitBreakerLastFailure = null;
    this.metrics = this.initializeMetrics();
    this.serializers = this.setupSerializers();
    this.retryManager = this.setupRetryManager();
    this.healthChecker = this.setupHealthChecker();
    
    this.initialize();
  }
  
  initializeMetrics() {
    return {
      messagesPublished: 0,
      messagesFailed: 0,
      messagesRetried: 0,
      batchesProcessed: 0,
      circuitBreakerTrips: 0,
      deadLetterMessages: 0,
      compressionRatio: 0,
      averageMessageSize: 0,
      averagePublishTime: 0,
      connectionFailures: 0,
      queueDepth: 0,
      throughputPerSecond: 0,
      startTime: Date.now()
    };
  }
  
  setupSerializers() {
    return {
      json: {
        serialize: (data) => JSON.stringify(data),
        deserialize: (data) => JSON.parse(data)
      },
      
      avro: {
        serialize: (data) => {
          // Avro serialization implementation
          const avro = require('avsc');
          const schema = avro.Type.forSchema({
            type: 'record',
            name: 'LogMessage',
            fields: [
              { name: 'timestamp', type: 'long' },
              { name: 'level', type: 'string' },
              { name: 'message', type: 'string' },
              { name: 'metadata', type: { type: 'map', values: 'string' } }
            ]
          });
          return schema.toBuffer(data);
        },
        deserialize: (buffer) => {
          const avro = require('avsc');
          // Avro deserialization implementation
          return avro.Type.fromBuffer(buffer);
        }
      },
      
      protobuf: {
        serialize: (data) => {
          // Protocol Buffers serialization
          const protobuf = require('protobufjs');
          // Implementation would depend on .proto schema
          return Buffer.from(JSON.stringify(data)); // Simplified
        },
        deserialize: (buffer) => {
          return JSON.parse(buffer.toString());
        }
      },
      
      msgpack: {
        serialize: (data) => {
          const msgpack = require('msgpack5')();
          return msgpack.encode(data);
        },
        deserialize: (buffer) => {
          const msgpack = require('msgpack5')();
          return msgpack.decode(buffer);
        }
      }
    };
  }
  
  setupRetryManager() {
    return {
      retryQueue: [],
      retryTimer: null,
      
      addForRetry: (message, attempt = 1) => {
        if (attempt <= this.options.maxRetries) {
          const retryMessage = {
            ...message,
            retryAttempt: attempt,
            retryScheduledAt: Date.now() + (attempt * this.options.deadLetterQueue.retryDelay)
          };
          
          this.retryManager.retryQueue.push(retryMessage);
          this.scheduleRetryProcessing();
        } else {
          this.sendToDeadLetterQueue(message);
        }
      },
      
      scheduleRetryProcessing: () => {
        if (!this.retryManager.retryTimer) {
          this.retryManager.retryTimer = setTimeout(() => {
            this.processRetryQueue();
          }, 1000);
        }
      },
      
      processRetryQueue: async () => {
        const now = Date.now();
        const readyMessages = this.retryManager.retryQueue.filter(
          msg => msg.retryScheduledAt <= now
        );
        
        this.retryManager.retryQueue = this.retryManager.retryQueue.filter(
          msg => msg.retryScheduledAt > now
        );
        
        for (const message of readyMessages) {
          try {
            await this.publishSingleMessage(message);
            this.metrics.messagesRetried++;
          } catch (error) {
            this.retryManager.addForRetry(message, message.retryAttempt + 1);
          }
        }
        
        this.retryManager.retryTimer = null;
        
        if (this.retryManager.retryQueue.length > 0) {
          this.retryManager.scheduleRetryProcessing();
        }
      }
    };
  }
  
  setupHealthChecker() {
    return {
      isHealthy: true,
      lastHealthCheck: Date.now(),
      
      performHealthCheck: async () => {
        try {
          const queueType = this.options.queueType;
          let healthy = false;
          
          switch (queueType) {
            case 'rabbitmq':
              healthy = await this.healthChecker.checkRabbitMQ();
              break;
            case 'kafka':
              healthy = await this.healthChecker.checkKafka();
              break;
            case 'redis':
              healthy = await this.healthChecker.checkRedis();
              break;
            case 'sqs':
              healthy = await this.healthChecker.checkSQS();
              break;
            case 'azure-servicebus':
              healthy = await this.healthChecker.checkAzureServiceBus();
              break;
            default:
              healthy = true;
          }
          
          this.healthChecker.isHealthy = healthy;
          this.healthChecker.lastHealthCheck = Date.now();
          
          if (!healthy) {
            this.emit('unhealthy', { queueType, timestamp: new Date() });
          }
          
          return healthy;
        } catch (error) {
          this.healthChecker.isHealthy = false;
          console.error('Health check failed:', error);
          return false;
        }
      },
      
      checkRabbitMQ: async () => {
        if (!this.queueClient || !this.queueClient.connection) return false;
        return this.queueClient.connection.isConnected();
      },
      
      checkKafka: async () => {
        if (!this.queueClient) return false;
        // Kafka admin client health check
        return true; // Simplified
      },
      
      checkRedis: async () => {
        if (!this.queueClient) return false;
        try {
          await this.queueClient.ping();
          return true;
        } catch {
          return false;
        }
      },
      
      checkSQS: async () => {
        if (!this.queueClient) return false;
        try {
          await this.queueClient.getQueueAttributes({
            QueueUrl: this.queueUrl,
            AttributeNames: ['QueueArn']
          }).promise();
          return true;
        } catch {
          return false;
        }
      },
      
      checkAzureServiceBus: async () => {
        if (!this.queueClient) return false;
        // Azure Service Bus health check implementation
        return true; // Simplified
      }
    };
  }
  
  async initialize() {
    try {
      await this.initializeConnection();
      await this.setupQueue();
      this.setupBatchProcessing();
      this.setupCircuitBreaker();
      
      if (this.options.enableHealthCheck) {
        this.setupPeriodicHealthCheck();
      }
      
      if (this.options.enableMetrics) {
        this.setupMetricsCollection();
      }
      
      console.log(`Queue logger initialized: ${this.options.queueType}`);
      
    } catch (error) {
      console.error('Failed to initialize queue logger:', error);
      throw error;
    }
  }
  
  async initializeConnection() {
    const queueType = this.options.queueType;
    
    switch (queueType) {
      case 'rabbitmq':
        await this.initializeRabbitMQ();
        break;
      case 'kafka':
        await this.initializeKafka();
        break;
      case 'redis':
        await this.initializeRedis();
        break;
      case 'sqs':
        await this.initializeSQS();
        break;
      case 'azure-servicebus':
        await this.initializeAzureServiceBus();
        break;
      case 'activemq':
        await this.initializeActiveMQ();
        break;
      default:
        throw new Error(`Unsupported queue type: ${queueType}`);
    }
  }
  
  async initializeRabbitMQ() {
    const amqp = require('amqplib');
    
    const connectionOptions = {
      protocol: 'amqp',
      hostname: this.options.connection.host || 'localhost',
      port: this.options.connection.port || 5672,
      username: this.options.connection.username || 'guest',
      password: this.options.connection.password || 'guest',
      vhost: this.options.connection.vhost || '/',
      heartbeat: this.options.connection.heartbeat || 60,
      ...this.options.connection
    };
    
    this.connection = await amqp.connect(connectionOptions);
    this.queueClient = await this.connection.createChannel();
    
    // Enable publisher confirms
    if (this.options.publishConfirms) {
      await this.queueClient.confirmSelect();
    }
    
    // Set prefetch count for better load distribution
    await this.queueClient.prefetch(this.options.batchSize);
    
    // Handle connection events
    this.connection.on('error', (error) => {
      console.error('RabbitMQ connection error:', error);
      this.handleConnectionError(error);
    });
    
    this.connection.on('close', () => {
      console.warn('RabbitMQ connection closed');
      this.handleConnectionClose();
    });
  }
  
  async initializeKafka() {
    const { Kafka } = require('kafkajs');
    
    const kafka = new Kafka({
      clientId: this.options.connection.clientId || 'queue-logger',
      brokers: this.options.connection.brokers || ['localhost:9092'],
      connectionTimeout: this.options.connection.connectionTimeout || 3000,
      authenticationTimeout: this.options.connection.authenticationTimeout || 1000,
      reauthenticationThreshold: this.options.connection.reauthenticationThreshold || 10000,
      ...this.options.connection
    });
    
    this.queueClient = kafka.producer({
      maxInFlightRequests: 1,
      idempotent: true,
      transactionTimeout: 30000,
      ...this.options.connection.producerOptions
    });
    
    await this.queueClient.connect();
    
    // Create topic if it doesn't exist
    const admin = kafka.admin();
    await admin.connect();
    
    try {
      await admin.createTopics({
        topics: [{
          topic: this.options.queueName,
          numPartitions: this.options.connection.partitions || 3,
          replicationFactor: this.options.connection.replicationFactor || 1
        }]
      });
    } catch (error) {
      // Topic might already exist
      console.log('Topic creation skipped:', error.message);
    }
    
    await admin.disconnect();
  }
  
  async initializeRedis() {
    const Redis = require('ioredis');
    
    const redisOptions = {
      host: this.options.connection.host || 'localhost',
      port: this.options.connection.port || 6379,
      password: this.options.connection.password,
      db: this.options.connection.db || 0,
      retryDelayOnFailover: 100,
      enableReadyCheck: false,
      maxRetriesPerRequest: 3,
      ...this.options.connection
    };
    
    this.queueClient = new Redis(redisOptions);
    
    this.queueClient.on('error', (error) => {
      console.error('Redis connection error:', error);
      this.handleConnectionError(error);
    });
    
    this.queueClient.on('connect', () => {
      console.log('Redis connected');
    });
  }
  
  async initializeSQS() {
    const AWS = require('aws-sdk');
    
    AWS.config.update({
      region: this.options.connection.region || 'us-east-1',
      accessKeyId: this.options.connection.accessKeyId,
      secretAccessKey: this.options.connection.secretAccessKey,
      ...this.options.connection
    });
    
    this.queueClient = new AWS.SQS({ apiVersion: '2012-11-05' });
    
    // Get or create queue URL
    try {
      const result = await this.queueClient.getQueueUrl({
        QueueName: this.options.queueName
      }).promise();
      
      this.queueUrl = result.QueueUrl;
    } catch (error) {
      if (error.code === 'AWS.SimpleQueueService.NonExistentQueue') {
        // Create queue
        const createResult = await this.queueClient.createQueue({
          QueueName: this.options.queueName,
          Attributes: {
            'MessageRetentionPeriod': '1209600', // 14 days
            'VisibilityTimeoutSeconds': '60',
            'ReceiveMessageWaitTimeSeconds': '20' // Long polling
          }
        }).promise();
        
        this.queueUrl = createResult.QueueUrl;
      } else {
        throw error;
      }
    }
  }
  
  async initializeAzureServiceBus() {
    const { ServiceBusClient } = require('@azure/service-bus');
    
    const connectionString = this.options.connection.connectionString;
    
    if (!connectionString) {
      throw new Error('Azure Service Bus connection string is required');
    }
    
    this.serviceBusClient = new ServiceBusClient(connectionString);
    this.queueClient = this.serviceBusClient.createSender(this.options.queueName);
    
    // Create queue if it doesn't exist
    const { ServiceBusAdministrationClient } = require('@azure/service-bus');
    const adminClient = new ServiceBusAdministrationClient(connectionString);
    
    try {
      await adminClient.createQueue(this.options.queueName, {
        maxDeliveryCount: this.options.maxRetries || 3,
        defaultMessageTimeToLive: this.options.ttl ? `PT${this.options.ttl}S` : 'P14D'
      });
    } catch (error) {
      // Queue might already exist
      console.log('Queue creation skipped:', error.message);
    }
  }
  
  async initializeActiveMQ() {
    const stompit = require('stompit');
    
    const connectOptions = {
      host: this.options.connection.host || 'localhost',
      port: this.options.connection.port || 61613,
      connectHeaders: {
        'host': '/',
        'login': this.options.connection.username || 'admin',
        'passcode': this.options.connection.password || 'admin',
        'heart-beat': '5000,5000'
      }
    };
    
    return new Promise((resolve, reject) => {
      stompit.connect(connectOptions, (error, client) => {
        if (error) {
          reject(error);
          return;
        }
        
        this.queueClient = client;
        
        client.on('error', (error) => {
          console.error('ActiveMQ connection error:', error);
          this.handleConnectionError(error);
        });
        
        resolve();
      });
    });
  }
  
  async setupQueue() {
    const queueType = this.options.queueType;
    
    switch (queueType) {
      case 'rabbitmq':
        await this.setupRabbitMQQueue();
        break;
      case 'kafka':
        // Kafka topics are created during initialization
        break;
      case 'redis':
        // Redis doesn't require queue setup
        break;
      case 'sqs':
        // SQS queue is created during initialization
        break;
      case 'azure-servicebus':
        // Azure Service Bus queue is created during initialization
        break;
      case 'activemq':
        // ActiveMQ doesn't require queue setup
        break;
    }
  }
  
  async setupRabbitMQQueue() {
    // Declare exchange
    await this.queueClient.assertExchange(
      this.options.exchangeName,
      'topic',
      { durable: true }
    );
    
    // Declare main queue
    const queueOptions = {
      durable: this.options.persistent,
      arguments: {}
    };
    
    if (this.options.ttl) {
      queueOptions.arguments['x-message-ttl'] = this.options.ttl * 1000;
    }
    
    if (this.options.deadLetterQueue.enabled) {
      queueOptions.arguments['x-dead-letter-exchange'] = this.options.exchangeName;
      queueOptions.arguments['x-dead-letter-routing-key'] = `dlq.${this.options.routingKey}`;
    }
    
    await this.queueClient.assertQueue(this.options.queueName, queueOptions);
    
    // Bind queue to exchange
    await this.queueClient.bindQueue(
      this.options.queueName,
      this.options.exchangeName,
      this.options.routingKey
    );
    
    // Setup dead letter queue if enabled
    if (this.options.deadLetterQueue.enabled) {
      await this.queueClient.assertQueue(
        this.options.deadLetterQueue.queueName,
        { durable: true }
      );
      
      await this.queueClient.bindQueue(
        this.options.deadLetterQueue.queueName,
        this.options.exchangeName,
        `dlq.${this.options.routingKey}`
      );
    }
  }
  
  setupBatchProcessing() {
    this.batchProcessor = {
      add: (logEntry) => {
        this.batchQueue.push(logEntry);
        
        if (this.batchQueue.length >= this.options.batchSize) {
          this.processBatch();
        } else if (!this.batchTimer) {
          this.batchTimer = setTimeout(() => {
            this.processBatch();
          }, this.options.batchTimeout);
        }
      },
      
      process: async () => {
        if (this.batchQueue.length === 0) return;
        
        const batch = [...this.batchQueue];
        this.batchQueue = [];
        
        if (this.batchTimer) {
          clearTimeout(this.batchTimer);
          this.batchTimer = null;
        }
        
        try {
          await this.publishBatch(batch);
          this.metrics.batchesProcessed++;
        } catch (error) {
          console.error('Batch processing failed:', error);
          this.handleBatchFailure(batch, error);
        }
      }
    };
  }
  
  setupCircuitBreaker() {
    this.circuitBreaker = {
      canExecute: () => {
        if (this.circuitBreakerState === 'OPEN') {
          const timeSinceLastFailure = Date.now() - this.circuitBreakerLastFailure;
          if (timeSinceLastFailure >= this.options.circuitBreaker.resetTimeout) {
            this.circuitBreakerState = 'HALF_OPEN';
            console.log('Circuit breaker moved to HALF_OPEN state');
          } else {
            return false;
          }
        }
        return true;
      },
      
      recordSuccess: () => {
        if (this.circuitBreakerState === 'HALF_OPEN') {
          this.circuitBreakerState = 'CLOSED';
          this.circuitBreakerFailures = 0;
          console.log('Circuit breaker CLOSED - recovered');
        }
      },
      
      recordFailure: () => {
        this.circuitBreakerFailures++;
        this.circuitBreakerLastFailure = Date.now();
        
        if (this.circuitBreakerFailures >= this.options.circuitBreaker.errorThreshold) {
          this.circuitBreakerState = 'OPEN';
          this.metrics.circuitBreakerTrips++;
          console.warn('Circuit breaker OPENED due to failures');
          this.emit('circuitBreakerOpen', {
            failures: this.circuitBreakerFailures,
            timestamp: new Date()
          });
        }
      }
    };
  }
  
  setupPeriodicHealthCheck() {
    setInterval(async () => {
      await this.healthChecker.performHealthCheck();
    }, 30000); // Every 30 seconds
  }
  
  setupMetricsCollection() {
    setInterval(() => {
      this.emitMetrics();
    }, 60000); // Every minute
  }
  
  async log(level, message, metadata = {}) {
    const logEntry = {
      timestamp: Date.now(),
      level: level.toUpperCase(),
      message,
      metadata: this.sanitizeMetadata(metadata),
      hostname: require('os').hostname(),
      pid: process.pid,
      service: process.env.SERVICE_NAME || 'unknown',
      version: process.env.APP_VERSION || '1.0.0'
    };
    
    this.batchProcessor.add(logEntry);
  }
  
  async publishBatch(batch) {
    if (!this.circuitBreaker.canExecute()) {
      throw new Error('Circuit breaker is OPEN');
    }
    
    const startTime = Date.now();
    
    try {
      const queueType = this.options.queueType;
      
      switch (queueType) {
        case 'rabbitmq':
          await this.publishRabbitMQBatch(batch);
          break;
        case 'kafka':
          await this.publishKafkaBatch(batch);
          break;
        case 'redis':
          await this.publishRedisBatch(batch);
          break;
        case 'sqs':
          await this.publishSQSBatch(batch);
          break;
        case 'azure-servicebus':
          await this.publishAzureServiceBusBatch(batch);
          break;
        case 'activemq':
          await this.publishActiveMQBatch(batch);
          break;
      }
      
      this.circuitBreaker.recordSuccess();
      this.updatePublishMetrics(batch, Date.now() - startTime);
      
    } catch (error) {
      this.circuitBreaker.recordFailure();
      this.metrics.messagesFailed += batch.length;
      throw error;
    }
  }
  
  async publishRabbitMQBatch(batch) {
    const promises = batch.map(logEntry => {
      const serializedMessage = this.serializeMessage(logEntry);
      const messageOptions = {
        persistent: this.options.persistent,
        priority: this.options.priority
      };
      
      if (this.options.ttl) {
        messageOptions.expiration = this.options.ttl * 1000;
      }
      
      if (this.options.publishConfirms) {
        return this.queueClient.publish(
          this.options.exchangeName,
          this.options.routingKey,
          serializedMessage,
          messageOptions
        );
      } else {
        this.queueClient.publish(
          this.options.exchangeName,
          this.options.routingKey,
          serializedMessage,
          messageOptions
        );
        return Promise.resolve();
      }
    });
    
    await Promise.all(promises);
  }
  
  async publishKafkaBatch(batch) {
    const messages = batch.map(logEntry => ({
      key: logEntry.metadata.correlationId || logEntry.metadata.requestId,
      value: this.serializeMessage(logEntry),
      partition: this.calculatePartition(logEntry),
      timestamp: logEntry.timestamp
    }));
    
    await this.queueClient.send({
      topic: this.options.queueName,
      messages
    });
  }
  
  async publishRedisBatch(batch) {
    const pipeline = this.queueClient.pipeline();
    
    batch.forEach(logEntry => {
      const serializedMessage = this.serializeMessage(logEntry);
      pipeline.lpush(this.options.queueName, serializedMessage);
    });
    
    await pipeline.exec();
  }
  
  async publishSQSBatch(batch) {
    // SQS supports batch sending up to 10 messages
    const batches = this.chunkArray(batch, 10);
    
    for (const sqsBatch of batches) {
      const entries = sqsBatch.map((logEntry, index) => ({
        Id: `msg-${Date.now()}-${index}`,
        MessageBody: this.serializeMessage(logEntry),
        DelaySeconds: 0
      }));
      
      await this.queueClient.sendMessageBatch({
        QueueUrl: this.queueUrl,
        Entries: entries
      }).promise();
    }
  }
  
  async publishAzureServiceBusBatch(batch) {
    const messages = batch.map(logEntry => ({
      body: this.serializeMessage(logEntry),
      messageId: `${logEntry.timestamp}-${Math.random()}`,
      timeToLive: this.options.ttl ? this.options.ttl * 1000 : undefined
    }));
    
    await this.queueClient.sendMessages(messages);
  }
  
  async publishActiveMQBatch(batch) {
    const promises = batch.map(logEntry => {
      return new Promise((resolve, reject) => {
        const frame = this.queueClient.send({
          destination: `/queue/${this.options.queueName}`,
          'content-type': 'application/json'
        });
        
        frame.write(this.serializeMessage(logEntry));
        frame.end();
        
        frame.on('error', reject);
        frame.on('finish', resolve);
      });
    });
    
    await Promise.all(promises);
  }
  
  async publishSingleMessage(logEntry) {
    return this.publishBatch([logEntry]);
  }
  
  serializeMessage(logEntry) {
    const serializer = this.serializers[this.options.serializer];
    
    if (!serializer) {
      throw new Error(`Unknown serializer: ${this.options.serializer}`);
    }
    
    const serialized = serializer.serialize(logEntry);
    
    if (this.options.compressionEnabled && Buffer.isBuffer(serialized)) {
      const zlib = require('zlib');
      return zlib.gzipSync(serialized);
    }
    
    return serialized;
  }
  
  calculatePartition(logEntry) {
    // Simple partition calculation based on correlation ID or timestamp
    const key = logEntry.metadata.correlationId || logEntry.timestamp.toString();
    const hash = require('crypto').createHash('md5').update(key).digest('hex');
    const partitionCount = this.options.connection.partitions || 3;
    return parseInt(hash.substring(0, 8), 16) % partitionCount;
  }
  
  chunkArray(array, size) {
    const chunks = [];
    for (let i = 0; i < array.length; i += size) {
      chunks.push(array.slice(i, i + size));
    }
    return chunks;
  }
  
  sanitizeMetadata(metadata) {
    if (typeof metadata !== 'object' || metadata === null) {
      return {};
    }
    
    const sanitized = { ...metadata };
    const sensitiveKeys = ['password', 'token', 'apikey', 'secret', 'auth', 'authorization'];
    
    Object.keys(sanitized).forEach(key => {
      const lowerKey = key.toLowerCase();
      
      if (sensitiveKeys.some(sensitive => lowerKey.includes(sensitive))) {
        sanitized[key] = '[REDACTED]';
      }
    });
    
    return sanitized;
  }
  
  updatePublishMetrics(batch, publishTime) {
    this.metrics.messagesPublished += batch.length;
    
    // Update average publish time
    const avgTime = this.metrics.averagePublishTime;
    const count = this.metrics.batchesProcessed + 1;
    this.metrics.averagePublishTime = (avgTime * (count - 1) + publishTime) / count;
    
    // Update average message size
    const totalSize = batch.reduce((sum, entry) => {
      return sum + JSON.stringify(entry).length;
    }, 0);
    
    const avgSize = this.metrics.averageMessageSize;
    const msgCount = this.metrics.messagesPublished;
    this.metrics.averageMessageSize = 
      (avgSize * (msgCount - batch.length) + totalSize) / msgCount;
  }
  
  handleBatchFailure(batch, error) {
    console.error('Batch failure:', error);
    
    // Add to retry queue
    batch.forEach(logEntry => {
      this.retryManager.addForRetry(logEntry);
    });
  }
  
  async sendToDeadLetterQueue(message) {
    try {
      this.metrics.deadLetterMessages++;
      
      const dlqMessage = {
        ...message,
        originalFailureTime: Date.now(),
        failureReason: 'Max retries exceeded'
      };
      
      // Send to dead letter queue based on queue type
      const queueType = this.options.queueType;
      
      switch (queueType) {
        case 'rabbitmq':
          await this.queueClient.publish(
            this.options.exchangeName,
            `dlq.${this.options.routingKey}`,
            Buffer.from(JSON.stringify(dlqMessage)),
            { persistent: true }
          );
          break;
          
        case 'kafka':
          await this.queueClient.send({
            topic: `${this.options.queueName}-dlq`,
            messages: [{
              value: JSON.stringify(dlqMessage)
            }]
          });
          break;
          
        case 'redis':
          await this.queueClient.lpush(
            `${this.options.queueName}-dlq`,
            JSON.stringify(dlqMessage)
          );
          break;
          
        case 'sqs':
          // SQS DLQ is configured at queue level
          break;
          
        case 'azure-servicebus':
          // Azure Service Bus DLQ is automatic
          break;
      }
      
      console.warn('Message sent to dead letter queue:', dlqMessage);
      this.emit('deadLetter', dlqMessage);
      
    } catch (error) {
      console.error('Failed to send message to dead letter queue:', error);
    }
  }
  
  handleConnectionError(error) {
    this.metrics.connectionFailures++;
    console.error('Connection error:', error);
    this.emit('connectionError', error);
  }
  
  handleConnectionClose() {
    console.warn('Connection closed');
    this.emit('connectionClosed');
  }
  
  async processBatch() {
    return this.batchProcessor.process();
  }
  
  emitMetrics() {
    const uptime = Date.now() - this.metrics.startTime;
    const metricsSnapshot = {
      ...this.metrics,
      uptime,
      messagesPerSecond: this.metrics.messagesPublished / (uptime / 1000),
      batchesPerSecond: this.metrics.batchesProcessed / (uptime / 1000),
      averageBatchSize: this.metrics.messagesPublished / Math.max(this.metrics.batchesProcessed, 1),
      failureRate: this.metrics.messagesFailed / Math.max(this.metrics.messagesPublished, 1) * 100,
      retryRate: this.metrics.messagesRetried / Math.max(this.metrics.messagesPublished, 1) * 100,
      deadLetterRate: this.metrics.deadLetterMessages / Math.max(this.metrics.messagesPublished, 1) * 100,
      circuitBreakerState: this.circuitBreakerState,
      isHealthy: this.healthChecker.isHealthy,
      queueDepth: this.batchQueue.length
    };
    
    this.emit('metrics', metricsSnapshot);
  }
  
  // Convenience methods
  trace(message, metadata) { return this.log('trace', message, metadata); }
  debug(message, metadata) { return this.log('debug', message, metadata); }
  info(message, metadata) { return this.log('info', message, metadata); }
  warn(message, metadata) { return this.log('warn', message, metadata); }
  error(message, metadata) { return this.log('error', message, metadata); }
  fatal(message, metadata) { return this.log('fatal', message, metadata); }
  
  // Management methods
  async flush() {
    await this.processBatch();
    await this.retryManager.processRetryQueue();
  }
  
  getMetrics() {
    return { ...this.metrics };
  }
  
  async getHealth() {
    const isHealthy = await this.healthChecker.performHealthCheck();
    
    return {
      healthy: isHealthy,
      queueType: this.options.queueType,
      circuitBreakerState: this.circuitBreakerState,
      metrics: this.getMetrics(),
      queueDepth: this.batchQueue.length,
      retryQueueDepth: this.retryManager.retryQueue.length
    };
  }
  
  // Cleanup
  async destroy() {
    try {
      // Flush remaining messages
      await this.flush();
      
      // Clear timers
      if (this.batchTimer) {
        clearTimeout(this.batchTimer);
      }
      
      if (this.retryManager.retryTimer) {
        clearTimeout(this.retryManager.retryTimer);
      }
      
      // Close queue connections
      const queueType = this.options.queueType;
      
      switch (queueType) {
        case 'rabbitmq':
          if (this.queueClient) {
            await this.queueClient.close();
          }
          if (this.connection) {
            await this.connection.close();
          }
          break;
          
        case 'kafka':
          if (this.queueClient) {
            await this.queueClient.disconnect();
          }
          break;
          
        case 'redis':
          if (this.queueClient) {
            this.queueClient.disconnect();
          }
          break;
          
        case 'azure-servicebus':
          if (this.queueClient) {
            await this.queueClient.close();
          }
          if (this.serviceBusClient) {
            await this.serviceBusClient.close();
          }
          break;
          
        case 'activemq':
          if (this.queueClient) {
            this.queueClient.disconnect();
          }
          break;
      }
      
      console.log('Queue logger destroyed');
    } catch (error) {
      console.error('Error during queue logger destruction:', error);
    }
  }
}
```

### 2. **Queue-Specific Optimizations**
Specialized configurations for different message queue systems.

```javascript
// Queue-specific optimization implementations
class QueueOptimizations {
  
  // RabbitMQ optimizations
  static createRabbitMQOptimizer(logger) {
    return {
      setupHighThroughputConfiguration: async () => {
        // Optimize for high throughput logging
        const optimizations = {
          // Connection-level optimizations
          frameMax: 131072, // 128KB frames
          heartbeat: 600,   // 10 minutes
          channelMax: 2047,
          
          // Queue-level optimizations
          queueOptions: {
            durable: true,
            arguments: {
              'x-queue-mode': 'lazy', // For high message volumes
              'x-max-length': 1000000, // Limit queue size
              'x-overflow': 'drop-head' // Drop old messages if full
            }
          },
          
          // Publisher optimizations
          publisherConfirms: true,
          mandatoryPublishing: false,
          immediatePublishing: false
        };
        
        return optimizations;
      },
      
      setupPersistenceOptimization: () => {
        return {
          // Persistence settings for durability
          exchangeOptions: {
            durable: true,
            autoDelete: false
          },
          
          queueOptions: {
            durable: true,
            exclusive: false,
            autoDelete: false,
            arguments: {
              'x-queue-mode': 'default', // For persistence
              'x-message-ttl': 86400000 // 24 hours
            }
          },
          
          messageOptions: {
            persistent: true,
            deliveryMode: 2
          }
        };
      },
      
      setupClusterConfiguration: () => {
        return {
          // High availability cluster setup
          policies: [
            {
              name: 'logs-ha-policy',
              pattern: 'logs.*',
              definition: {
                'ha-mode': 'exactly',
                'ha-params': 2,
                'ha-sync-mode': 'automatic'
              }
            }
          ],
          
          federationUpstreams: [
            {
              name: 'remote-logs',
              uri: 'amqp://remote-cluster:5672',
              expires: 3600000
            }
          ]
        };
      }
    };
  }
  
  // Kafka optimizations
  static createKafkaOptimizer(logger) {
    return {
      setupHighThroughputConfiguration: () => {
        return {
          // Producer configuration for high throughput
          producerConfig: {
            'acks': '1', // Wait for leader acknowledgment only
            'batch.size': 16384, // 16KB batch size
            'linger.ms': 10, // Wait up to 10ms to batch messages
            'compression.type': 'snappy', // Fast compression
            'buffer.memory': 33554432, // 32MB buffer
            'max.in.flight.requests.per.connection': 5,
            'retries': 3,
            'delivery.timeout.ms': 30000
          },
          
          // Topic configuration
          topicConfig: {
            'num.partitions': 12, // Increase parallelism
            'replication.factor': 3,
            'min.insync.replicas': 2,
            'cleanup.policy': 'delete',
            'retention.ms': 604800000, // 7 days
            'segment.ms': 86400000 // 1 day segments
          }
        };
      },
      
      setupPartitioningStrategy: (logEntry) => {
        // Intelligent partitioning for load distribution
        const strategies = {
          byService: () => {
            const service = logEntry.metadata.service || 'default';
            return require('crypto').createHash('md5')
              .update(service).digest('hex').substring(0, 8);
          },
          
          byLogLevel: () => {
            const levelWeights = {
              'ERROR': 0, 'FATAL': 0,    // Critical logs to partition 0
              'WARN': 1,                 // Warnings to partition 1
              'INFO': 2, 'DEBUG': 2, 'TRACE': 2 // Others distributed
            };
            return levelWeights[logEntry.level] || 2;
          },
          
          byTimeWindow: () => {
            // Distribute by time windows for even distribution
            const timeWindow = Math.floor(Date.now() / (5 * 60 * 1000)); // 5-minute windows
            return timeWindow % 12; // Assuming 12 partitions
          }
        };
        
        return strategies.byService();
      }
    };
  }
  
  // Redis optimizations
  static createRedisOptimizer(logger) {
    return {
      setupHighPerformanceConfiguration: () => {
        return {
          // Redis configuration for logging workload
          redisConfig: {
            // Memory optimization
            'maxmemory-policy': 'allkeys-lru',
            'maxmemory': '2gb',
            
            // Persistence optimization
            'save': '900 1 300 10 60 10000', // RDB snapshots
            'appendonly': 'yes',
            'appendfsync': 'everysec',
            'no-appendfsync-on-rewrite': 'yes',
            
            // Performance optimization
            'tcp-keepalive': 60,
            'timeout': 0,
            'tcp-backlog': 511,
            'databases': 16
          },
          
          // Connection pool optimization
          poolConfig: {
            max: 20,
            min: 5,
            acquireTimeoutMillis: 30000,
            idleTimeoutMillis: 30000,
            reapIntervalMillis: 1000,
            createRetryIntervalMillis: 200
          }
        };
      },
      
      setupStreamBasedLogging: () => {
        return {
          // Use Redis Streams for ordered logging
          streamConfig: {
            streamName: 'application-logs',
            maxLength: 1000000, // Limit stream size
            trimming: 'MAXLEN',
            approximate: true
          },
          
          consumerGroupConfig: {
            groupName: 'log-processors',
            consumerName: 'processor-1',
            readCount: 100,
            blockTime: 1000
          }
        };
      }
    };
  }
  
  // AWS SQS optimizations
  static createSQSOptimizer(logger) {
    return {
      setupOptimalConfiguration: () => {
        return {
          // Queue attributes for logging
          queueAttributes: {
            'MessageRetentionPeriod': '1209600', // 14 days
            'VisibilityTimeoutSeconds': '60',
            'MaxReceiveCount': '3', // For DLQ
            'ReceiveMessageWaitTimeSeconds': '20', // Long polling
            'DelaySeconds': '0'
          },
          
          // Dead letter queue configuration
          deadLetterQueueAttributes: {
            'MessageRetentionPeriod': '1209600' // 14 days
          },
          
          // Batch processing optimization
          batchConfig: {
            maxBatchSize: 10, // SQS limit
            maxWaitTime: 1000, // 1 second
            maxMessageSize: 262144 // 256KB
          },
          
          // FIFO queue configuration (if ordering is required)
          fifoConfig: {
            contentBasedDeduplication: true,
            messageGroupId: 'log-group-1',
            deduplicationScope: 'messageGroup'
          }
        };
      }
    };
  }
}
```

## Message Queue Logging Best Practices

### **Production Queue Logging Setup**
```javascript
// Production-ready queue logging configuration
class ProductionQueueLogger {
  constructor(options = {}) {
    this.environment = process.env.NODE_ENV || 'development';
    this.queueType = options.queueType || 'rabbitmq';
    
    const config = this.getEnvironmentConfig();
    
    this.logger = new AdvancedQueueLogger({
      ...config,
      ...options,
      
      // Production optimizations
      batchSize: this.environment === 'production' ? 1000 : 100,
      batchTimeout: this.environment === 'production' ? 10000 : 5000,
      
      // Circuit breaker for production resilience
      circuitBreaker: {
        errorThreshold: 10,
        timeout: 60000,
        resetTimeout: 30000
      },
      
      // Dead letter queue for production
      deadLetterQueue: {
        enabled: true,
        maxRetries: 3,
        retryDelay: 5000
      },
      
      // Compression for network efficiency
      compressionEnabled: this.environment === 'production',
      
      // Monitoring enabled
      enableMetrics: true,
      enableHealthCheck: true
    });
    
    this.setupProductionFeatures();
  }
  
  getEnvironmentConfig() {
    const configs = {
      development: {
        queueType: 'redis',
        connection: {
          host: 'localhost',
          port: 6379
        },
        queueName: 'dev-logs',
        batchSize: 10
      },
      
      testing: {
        queueType: 'redis',
        connection: {
          host: 'localhost',
          port: 6379,
          db: 1
        },
        queueName: 'test-logs',
        batchSize: 5
      },
      
      production: {
        queueType: 'rabbitmq',
        connection: {
          host: process.env.RABBITMQ_HOST,
          port: parseInt(process.env.RABBITMQ_PORT) || 5672,
          username: process.env.RABBITMQ_USER,
          password: process.env.RABBITMQ_PASSWORD,
          vhost: process.env.RABBITMQ_VHOST || '/',
          heartbeat: 60
        },
        queueName: 'production-logs',
        exchangeName: 'logs-exchange',
        routingKey: 'logs.application',
        batchSize: 1000,
        persistent: true,
        publishConfirms: true
      }
    };
    
    return configs[this.environment] || configs.development;
  }
  
  setupProductionFeatures() {
    // Monitor queue health
    this.logger.on('metrics', (metrics) => {
      this.handleMetrics(metrics);
    });
    
    this.logger.on('circuitBreakerOpen', (info) => {
      console.error('Circuit breaker opened:', info);
      this.alertOnCircuitBreaker(info);
    });
    
    this.logger.on('deadLetter', (message) => {
      console.warn('Message sent to DLQ:', message);
      this.alertOnDeadLetter(message);
    });
    
    this.logger.on('connectionError', (error) => {
      console.error('Queue connection error:', error);
      this.alertOnConnectionError(error);
    });
    
    // Setup graceful shutdown
    process.on('SIGTERM', () => this.gracefulShutdown());
    process.on('SIGINT', () => this.gracefulShutdown());
  }
  
  handleMetrics(metrics) {
    if (this.environment === 'production') {
      // Send metrics to monitoring system
      this.sendMetricsToMonitoring(metrics);
      
      // Check for alerts
      if (metrics.failureRate > 5) {
        this.alertOnHighFailureRate(metrics);
      }
      
      if (metrics.averagePublishTime > 1000) {
        this.alertOnHighLatency(metrics);
      }
      
      if (metrics.queueDepth > 10000) {
        this.alertOnHighQueueDepth(metrics);
      }
    }
  }
  
  sendMetricsToMonitoring(metrics) {
    // Implementation depends on monitoring system
    const monitoringData = {
      service: 'queue-logger',
      environment: this.environment,
      queueType: this.queueType,
      metrics: {
        'messages.published': metrics.messagesPublished,
        'messages.failed': metrics.messagesFailed,
        'messages.per_second': metrics.messagesPerSecond,
        'publish.latency_avg': metrics.averagePublishTime,
        'batch.size_avg': metrics.averageBatchSize,
        'failure.rate': metrics.failureRate,
        'retry.rate': metrics.retryRate,
        'dead_letter.rate': metrics.deadLetterRate,
        'queue.depth': metrics.queueDepth,
        'circuit_breaker.state': metrics.circuitBreakerState === 'CLOSED' ? 0 : 1
      },
      timestamp: Date.now()
    };
    
    console.log('Queue Metrics:', monitoringData);
  }
  
  alertOnCircuitBreaker(info) {
    // Send alert to monitoring system
    console.error('ALERT: Queue logger circuit breaker opened', info);
  }
  
  alertOnDeadLetter(message) {
    // Send alert for dead letter messages
    console.warn('ALERT: Message sent to dead letter queue', {
      level: message.level,
      service: message.service,
      timestamp: new Date(message.timestamp)
    });
  }
  
  alertOnConnectionError(error) {
    // Send alert for connection errors
    console.error('ALERT: Queue connection error', error.message);
  }
  
  alertOnHighFailureRate(metrics) {
    console.warn('ALERT: High message failure rate detected', {
      failureRate: metrics.failureRate,
      messagesFailed: metrics.messagesFailed
    });
  }
  
  alertOnHighLatency(metrics) {
    console.warn('ALERT: High publish latency detected', {
      averagePublishTime: metrics.averagePublishTime
    });
  }
  
  alertOnHighQueueDepth(metrics) {
    console.warn('ALERT: High queue depth detected', {
      queueDepth: metrics.queueDepth
    });
  }
  
  async gracefulShutdown() {
    console.log('Initiating graceful shutdown of queue logger...');
    
    try {
      // Flush remaining messages
      await this.logger.flush();
      
      // Give some time for final processing
      await new Promise(resolve => setTimeout(resolve, 2000));
      
      // Destroy the logger
      await this.logger.destroy();
      
      console.log('Queue logger shutdown completed');
      process.exit(0);
    } catch (error) {
      console.error('Error during graceful shutdown:', error);
      process.exit(1);
    }
  }
  
  // Logging interface
  async log(level, message, metadata = {}) {
    // Add production context
    const enrichedMetadata = {
      ...metadata,
      environment: this.environment,
      service: process.env.SERVICE_NAME || 'unknown',
      version: process.env.APP_VERSION || '1.0.0',
      instance: require('os').hostname(),
      correlationId: metadata.correlationId || this.generateCorrelationId()
    };
    
    return this.logger.log(level, message, enrichedMetadata);
  }
  
  generateCorrelationId() {
    return `${Date.now()}-${Math.random().toString(36).substring(2, 15)}`;
  }
  
  // Convenience methods
  info(message, metadata) { return this.log('info', message, metadata); }
  warn(message, metadata) { return this.log('warn', message, metadata); }
  error(message, metadata) { return this.log('error', message, metadata); }
  debug(message, metadata) { return this.log('debug', message, metadata); }
  
  // Health check
  async getHealth() {
    return this.logger.getHealth();
  }
  
  // Metrics
  getMetrics() {
    return this.logger.getMetrics();
  }
  
  // Cleanup
  async destroy() {
    await this.logger.destroy();
  }
}

// Usage example
const queueLogger = new ProductionQueueLogger({
  queueType: 'rabbitmq',
  connection: {
    host: process.env.RABBITMQ_HOST,
    port: 5672,
    username: process.env.RABBITMQ_USER,
    password: process.env.RABBITMQ_PASSWORD
  }
});

// Application logging
queueLogger.info('Application started', { 
  port: 3000,
  correlationId: 'app-start-001' 
});

queueLogger.error('Payment processing failed', { 
  orderId: '12345',
  amount: 99.99,
  error: 'Gateway timeout',
  correlationId: 'payment-001'
});

// Health monitoring
const health = await queueLogger.getHealth();
console.log('Queue logger health:', health);

// Metrics monitoring
const metrics = queueLogger.getMetrics();
console.log('Queue logger metrics:', metrics);
```

---

**Previous**: [2.3.4 Databases](./2.3.4_Databases.md)  
**Next**: [2.3.6 Cloud Services](./2.3.6_Cloud_Services.md)
